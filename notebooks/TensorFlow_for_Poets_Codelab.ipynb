{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow for Poets Codelab\n",
    "\n",
    "This codelab was produced by Google. The original can be found here:\n",
    "\n",
    "https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/?utm_campaign=chrome_series_machinelearning_063016&utm_source=gdev&utm_medium=yt-desc#0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start TensorBoard\n",
    "\n",
    "Before starting the training, launch tensorboard in the background. TensorBoard is a monitoring and inspection tool included with tensorflow. You will use it to monitor the training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tensorboard --logdir tf_files/training_summaries &`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Settings\n",
    "\n",
    "Pick the following configuration options:\n",
    "\n",
    "Input image resolution: 128,160,192, or 224px. Unsurprisingly, feeding in a higher resolution image takes more processing time, but results in better classification accuracy. We recommend 224 as an initial setting.\n",
    "\n",
    "The relative size of the model as a fraction of the largest MobileNet: 1.0, 0.75, 0.50, or 0.25. We recommend 0.5 as an initial setting. The smaller models run significantly faster, at a cost of accuracy.\n",
    "\n",
    "With the recommended settings, it typically takes only a couple of minutes to retrain on a laptop. You will pass the settings inside Linux shell variables. Set those shell variables as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IMAGE_SIZE=224\n",
    "ARCHITECTURE=\"mobilenet_0.50_${IMAGE_SIZE}\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the retraining script\n",
    "\n",
    "The retrain script is part of the tensorflow repo, but it is not installed as part of the pip package. So for simplicity I've included it in the codelab repository. You can run the script using the python command. Take a minute to skim its \"help\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python -m scripts.retrain -h`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training\n",
    "\n",
    "As noted in the introduction, Imagenet models are networks with millions of parameters that can differentiate a large number of classes. We're only training the final layer of that network, so training will end in a reasonable amount of time.\n",
    "\n",
    "Start your retraining with one big command (note the --summaries_dir option, sending training progress reports to the directory that tensorboard is monitoring):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python -m scripts.retrain \\\n",
    "  --bottleneck_dir=tf_files/bottlenecks \\\n",
    "  --how_many_training_steps=500 \\\n",
    "  --model_dir=tf_files/models/ \\\n",
    "  --summaries_dir=tf_files/training_summaries/\"${ARCHITECTURE}\" \\\n",
    "  --output_graph=tf_files/retrained_graph.pb \\\n",
    "  --output_labels=tf_files/retrained_labels.txt \\\n",
    "  --architecture=\"${ARCHITECTURE}\" \\\n",
    "  --image_dir=tf_files/flower_photos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script downloads the pre-trained model, adds a new final layer, and trains that layer on the flower photos you've downloaded. \n",
    "\n",
    "ImageNet does not include any of these flower species we're training on here. However, the kinds of information that make it possible for ImageNet to differentiate among 1,000 classes are also useful for distinguishing other objects. By using this pre-trained network, we are using that information as input to the final classification layer that distinguishes our flower classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Retrained Model\n",
    "\n",
    "The retraining script writes data to the following two files:\n",
    "\n",
    "- tf_files/retrained_graph.pb, which contains a version of the selected network with a final layer retrained on your categories.\n",
    "\n",
    "- tf_files/retrained_labels.txt, which is a text file containing labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying an image\n",
    "\n",
    "The codelab repo also contains a copy of tensorflow's label_image.py example, which you can use to test your network. Take a minute to read the help for this script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python -m  scripts.label_image -h`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this Python program takes quite a few arguments. The defaults are all set for this project, but if you used a MobileNet architecture with a different image size you will need to set the --input_size argument using the variable you created earlier: --input_size=${IMAGE_SIZE}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python -m scripts.label_image \\\n",
    "    --graph=tf_files/retrained_graph.pb  \\\n",
    "    --image=tf_files/flower_photos/daisy/21652746_cc379e0eea_m.jpg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the script on this image of a daisy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python -m scripts.label_image \\\n",
    "    --graph=tf_files/retrained_graph.pb  \\\n",
    "    --image=tf_files/flower_photos/daisy/21652746_cc379e0eea_m.jpg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each execution will print a list of flower labels, in most cases with the correct flower on top (though each retrained model may be slightly different).\n",
    "\n",
    "You might get results like this for a daisy photo:\n",
    "\n",
    "`daisy (score = 0.99071)\n",
    "sunflowers (score = 0.00595)\n",
    "dandelion (score = 0.00252)\n",
    "roses (score = 0.00049)\n",
    "tulips (score = 0.00032)`\n",
    "\n",
    "This indicates a high confidence (~99%) that the image is a daisy, and low confidence for any other label.\n",
    "\n",
    "You can use label_image.py to classify any image file you choose, either from your downloaded collection, or new ones. You just have to change the `--image` file name argument to the script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Other Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retraining script has several other command line options you can use.\n",
    "\n",
    "You can read about these options in the help for the retrain script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python -m scripts.retrain -h`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adjusting some of these options to see if you can increase the final validation accuracy.\n",
    "\n",
    "For example, the `--learning_rate` parameter controls the magnitude of the updates to the final layer during training. So far we have left it out, so the program has used the default learning_rate value of 0.01. If you specify a small learning_rate, like 0.005, the training will take longer, but the overall precision might increase. Higher values of learning_rate, like 1.0, could train faster, but typically reduces precision, or even makes training unstable.\n",
    "\n",
    "You need to experiment carefully to see what works for your case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very helpful for this type of work if you give each experiment a unique name, so they show up as separate entries in TensorBoard.\n",
    "\n",
    "It's the `--summaries_dir` option that controls the name in tensorboard. Earlier we used:\n",
    "\n",
    "`--summaries_dir=training_summaries/basic`\n",
    "\n",
    "TensorBoard is monitoring the contents of the training_summaries directory, so setting `--summarys_dir` to training_summaries or any subdirectory of training_summaries will work.\n",
    "\n",
    "You may want to set the following two options together, so your results are clearly labeled:\n",
    "\n",
    "`--learning_rate=0.5\n",
    "--summaries_dir=training_summaries/LR_0.5`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
