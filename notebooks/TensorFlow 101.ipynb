{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TensorFlow 101\n",
    "\n",
    "Getting Started with TensorFlow - https://www.tensorflow.org/get_started/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The TensorFlow programming stack\n",
    "\n",
    "As the following illustration shows, TensorFlow provides a programming stack consisting of multiple API layers:\n",
    "\n",
    "![](https://www.tensorflow.org/images/tensorflow_programming_environment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As you start writing TensorFlow programs, we strongly recommend focusing on the following two high-level APIs:\n",
    "\n",
    "- Estimators, which represent a complete model. The Estimator API provides methods to train the model, to judge the model's accuracy, and to generate predictions.\n",
    "\n",
    "- Datasets, which build a data input pipeline. The Dataset API has methods to load and manipulate data, and feed it into your model. The Dataset API meshes well with the Estimators API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The **training set** contains the examples that we'll use to train the model; the **test set** contains the examples that we'll use to evaluate the trained model's effectiveness.\n",
    "\n",
    "The training set and test set started out as a single data set. Then, someone split the examples, with the majority going into the training set and the remainder going into the test set. Adding examples to the training set usually builds a better model; however, adding more examples to the test set enables us to better gauge the model's effectiveness. Regardless of the split, the examples in the test set must be separate from the examples in the training set. Otherwise, you can't accurately determine the model's effectiveness.\n",
    "\n",
    "The premade_estimators.py program relies on the **load_data** function in the adjacent **project_name.py** file to read in and parse the training set and test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Algorithm\n",
    "\n",
    "The program trains a Deep Neural Network classifier model having the following topology:\n",
    "\n",
    "- 2 hidden layers.\n",
    "- Each hidden layer contains 10 nodes.\n",
    "\n",
    "The following figure illustrates the features, hidden layers, and predictions (not all of the nodes in the hidden layers are shown):\n",
    "\n",
    "![](https://www.tensorflow.org/images/custom_estimators/full_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview of programming with Estimators\n",
    "\n",
    "An Estimator is TensorFlow's high-level representation of a complete model. It handles the details of initialization, logging, saving and restoring, and many other features so you can concentrate on your model. For more details see Estimators.\n",
    "\n",
    "An Estimator is any class derived from tf.estimator.Estimator. TensorFlow provides a collection of pre-made Estimators (for example, LinearRegressor) to implement common ML algorithms. Beyond those, you may write your own custom Estimators. We recommend using pre-made Estimators when just getting started with TensorFlow. After gaining expertise with the pre-made Estimators, we recommend optimizing your model by creating your own custom Estimators.\n",
    "\n",
    "To write a TensorFlow program based on pre-made Estimators, you must perform the following tasks:\n",
    "\n",
    "- Create one or more input functions.\n",
    "- Define the model's feature columns.\n",
    "- Instantiate an Estimator, specifying the feature columns and various hyperparameters.\n",
    "- Call one or more methods on the Estimator object, passing the appropriate input function as the source of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating Input Functions\n",
    "\n",
    "You must create input functions to supply data for training, evaluating, and prediction.\n",
    "\n",
    "An input function is a function that returns a tf.data.Dataset object which outputs the following two-element tuple:\n",
    "\n",
    "- features - A Python dictionary in which:\n",
    "    - Each key is the name of a feature.\n",
    "    - Each value is an array containing all of that feature's values.\n",
    "- label - An array containing the values of the label for every example.\n",
    "\n",
    "Just to demonstrate the format of the input function, here's a simple implementation:\n",
    "\n",
    "```\n",
    "def input_evaluation_set():\n",
    "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
    "                'SepalWidth':  np.array([2.8, 2.3]),\n",
    "                'PetalLength': np.array([5.6, 3.3]),\n",
    "                'PetalWidth':  np.array([2.2, 1.0])}\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Your input function may generate the features dictionary and label list any way you like. However, we recommend using TensorFlow's Dataset API, which can parse all sorts of data. At a high level, the Dataset API consists of the following classes:\n",
    "\n",
    "![](https://www.tensorflow.org/images/dataset_classes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Where the individual members are:\n",
    "\n",
    "- Dataset - Base class containing methods to create and transform datasets. Also allows you to initialize a dataset from data in memory, or from a Python generator.\n",
    "- TextLineDataset - Reads lines from text files.\n",
    "- TFRecordDataset - Reads records from TFRecord files.\n",
    "- FixedLengthRecordDataset - Reads fixed size records from binary files.\n",
    "- Iterator - Provides a way to access one data set element at a time.\n",
    "\n",
    "The Dataset API can handle a lot of common cases for you. For example, using the Dataset API, you can easily read in records from a large collection of files in parallel and join them into a single stream.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define the feature columns\n",
    "\n",
    "A feature column is an object describing how the model should use raw input data from the features dictionary. When you build an Estimator model, you pass it a list of feature columns that describes each of the features you want the model to use. The tf.feature_column module provides many options for representing data to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Instantiate an estimator\n",
    "\n",
    "TensorFlow provides several pre-made classifier Estimators, including:\n",
    "\n",
    "- tf.estimator.DNNClassifier for deep models that perform multi-class classification.\n",
    "- tf.estimator.DNNLinearCombinedClassifier for wide & deep models.\n",
    "- tf.estimator.LinearClassifier for classifiers based on linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train, Evaluate, and Predict\n",
    "\n",
    "Now that we have an Estimator object, we can call methods to do the following:\n",
    "\n",
    "- Train the model.\n",
    "- Evaluate the trained model.\n",
    "- Use the trained model to make predictions."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
